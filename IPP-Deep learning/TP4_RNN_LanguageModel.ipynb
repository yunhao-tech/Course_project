{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPOXHysXKGLW"
      },
      "source": [
        "# Lab Deep Learning/ Recurrent Neural Networks/ in keras\n",
        "\n",
        "## Training language model (Many-to-Many) and generating sequences (One-to-Many)\n",
        "\n",
        "**Author: geoffroy.peeters@telecom-paris.fr**\n",
        "\n",
        "**Version**: \n",
        "- 2022/06/15 (changed to tensorfow.keras, added translation of questions in EN)\n",
        "- 2022/10/03 (added ReLU, np_epoch=20)\n",
        "\n",
        "For any remark or suggestion, please feel free to contact me.\n",
        "\n",
        "\n",
        "## Objective:\n",
        "\n",
        "- We will train a network to learn a language model and then use it to generate new sequences.\n",
        "\n",
        "- Instead of training the language model on text-documents (as it is the case in most examples) we will train it to learn the language of the music of [Johann_Sebastian_Bach](https://en.wikipedia.org/wiki/Johann_Sebastian_Bach).\n",
        "For this, we will learn how J. S. Bach's \"Cello suite\" have been composed.\n",
        "Here is an example of a \"Cello suite\" [Link](https://www.youtube.com/watch?v=mGQLXRTl3Z0).\n",
        "\n",
        "- Rather than analyzing the audio signal, we use a symbolic representation of the \"Cello suite\" through their [MIDI files](https://en.wikipedia.org/wiki/MIDI#MIDI_files).\n",
        "  - A MIDI file encodes in a file, the set of musical notes, their duration, and intensity which have to be played by each instrument to \"render\" a musical piece. The \"rendering\" is usually operated by a MIDI synthesizer (such as VLC, QuickTime).\n",
        "\n",
        "- We will first train a language model on the whole set of MIDI files of the \"Cello suites\". \n",
        "- We will then sample this language model to create a new MIDI file which will be a brand new \"Cello suite\" composed by the computer.\n",
        "\n",
        "### Questions:\n",
        "\n",
        "In the bottom part of this lab, you will have to answer a set of questions. Answers to those only necessitates a couple of sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjlvVXvgbpbW"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXocQU0HDntL"
      },
      "outputs": [],
      "source": [
        "! pip install pretty_midi\n",
        "\n",
        "import os\n",
        "import pretty_midi\n",
        "from scipy.io import wavfile \n",
        "import IPython\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Flatten, Dropout, Activation\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "student = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6YQL6s5j93E"
      },
      "source": [
        "# Get the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gZx9igIOvtU"
      },
      "outputs": [],
      "source": [
        "n_x = 79\n",
        "max_T_x = 1000\n",
        "sequence_length = 20\n",
        "T_y_generated = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgG1EmxKDhE5"
      },
      "source": [
        "## Collect data to create the language model\n",
        "\n",
        "We download the 36 MIDI files corresponding to the 36 \"Cello suites\" composed by J. S. Bach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9Tgx3ooDgSP"
      },
      "outputs": [],
      "source": [
        "DIR = './'\n",
        "import urllib.request\n",
        "midiFile_l = ['cs1-2all.mid', 'cs5-1pre.mid', 'cs4-1pre.mid', 'cs3-5bou.mid', 'cs1-4sar.mid', 'cs2-5men.mid', 'cs3-3cou.mid', 'cs2-3cou.mid', 'cs1-6gig.mid', 'cs6-4sar.mid', 'cs4-5bou.mid', 'cs4-3cou.mid', 'cs5-3cou.mid', 'cs6-5gav.mid', 'cs6-6gig.mid', 'cs6-2all.mid', 'cs2-1pre.mid', 'cs3-1pre.mid', 'cs3-6gig.mid', 'cs2-6gig.mid', 'cs2-4sar.mid', 'cs3-4sar.mid', 'cs1-5men.mid', 'cs1-3cou.mid', 'cs6-1pre.mid', 'cs2-2all.mid', 'cs3-2all.mid', 'cs1-1pre.mid', 'cs5-2all.mid', 'cs4-2all.mid', 'cs5-5gav.mid', 'cs4-6gig.mid', 'cs5-6gig.mid', 'cs5-4sar.mid', 'cs4-4sar.mid', 'cs6-3cou.mid']\n",
        "for midiFile in midiFile_l:\n",
        "  #if os.path.isfile(DIR + midiFile) is None:\n",
        "  urllib.request.urlretrieve (\"http://www.jsbach.net/midi/\" + midiFile, DIR + midiFile)\n",
        "nbExample = len(midiFile_l)\n",
        "\n",
        "midiFile_l = glob.glob(DIR + 'cs*.mid')\n",
        "print(midiFile_l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgCE_6urcVsj"
      },
      "source": [
        "## Read and convert all MIDI files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEg5c8wfj93K"
      },
      "outputs": [],
      "source": [
        "# --- Read a single MIDI file\n",
        "midi_data = pretty_midi.PrettyMIDI(midiFile_l[0])\n",
        "# --- Display the note pitch, start, end and duration\n",
        "for note in midi_data.instruments[0].notes:\n",
        "    print('pitch: %d, start: %f, end: %f, duration: %f' % (note.pitch, note.start, note.end, note.end-note.start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDofyEKjcd4E"
      },
      "source": [
        "We read all MIDI files and convert their content to one-hot-encoding matrix X_ohe of dimensions (T_x, n_x) where n_x is the number of possible musical notes.\n",
        "The duration of the sequences T_x can vary from one sequence to the other.\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EirVcbKxEe-3"
      },
      "outputs": [],
      "source": [
        "# --- We truncate the duration of each example to the first T_x data\n",
        "\n",
        "X_list = []\n",
        "\n",
        "for midiFile in midiFile_l:\n",
        "    # read the MIDI file\n",
        "    midi_data = pretty_midi.PrettyMIDI(midiFile)\n",
        "    note_l = [note.pitch for note in midi_data.instruments[0].notes]\n",
        "    # convert to one-hot-encoding\n",
        "    T_x = len(note_l)\n",
        "    if T_x > max_T_x:\n",
        "        T_x = max_T_x\n",
        "    X_ohe = np.zeros((T_x, n_x))\n",
        "    for t in range(T_x): \n",
        "        X_ohe[t, note_l[t]-1] = 1\n",
        "    # add to the list  \n",
        "    X_list.append(X_ohe)\n",
        "    \n",
        "print(len(X_list))\n",
        "print(X_list[0].shape)\n",
        "print(X_list[1].shape)\n",
        "print(X_list[2].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSf8RDL5cv7V"
      },
      "source": [
        "## Display the set of notes over time for a specific track "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wesPFMZHcvKG"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 6))\n",
        "plt.imshow(X_list[2].T, aspect='auto')\n",
        "plt.set_cmap('gray_r')\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMHtioR_c5y3"
      },
      "source": [
        "## Data conversion for the training of language model\n",
        "\n",
        "For each example/sequence and each possible starting note in this example/sequence, we create two sequences\n",
        "- an input sequence: \n",
        "  - which contains a sub-sequence of length ```sequence_length```;  this sub-sequence range from the note $t$ to the note $t+sequence\\_length-1$\n",
        "- an output sequence:\n",
        "  - which contains the following note to be predicted, the one at position $t+sequence\\_length$\n",
        "\n",
        "The training is therefore performed by giving to the model a set of sequences as input and asking the network to predict each time the note that should come right after this sequence.\n",
        "\n",
        "<img src=\"https://perso.telecom-paristech.fr/gpeeters/doc/Lab_DL_RNN_02.png\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGzvp4RCC0XX"
      },
      "outputs": [],
      "source": [
        "X_train_list = []\n",
        "y_train_list = []\n",
        "\n",
        "if student:\n",
        "    # --- START CODE HERE (01)\n",
        "    True\n",
        "    # --- END CODE HERE\n",
        "\n",
        "X_train = np.asarray(X_train_list)\n",
        "y_train = np.asarray(y_train_list)\n",
        "\n",
        "print(\"X_train.shape:\", X_train.shape)\n",
        "print(\"y_train.shape:\", y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhNPrmvveuH3"
      },
      "source": [
        "# Training the language model\n",
        "\n",
        "The language model will be learned by training an RNN with input `X_train` and output `Y_train`:  for each of the examples of sequences, we give to the network a sequence of notes of `sequence_length` duration, and ask the network to predict the following note of each sequence.\n",
        "\n",
        "The network will have the following structure\n",
        "- (1a) a layer of `LSTM` with $n_a$=256\n",
        "- (1b) a layer of DropOut with rate 0.3 (the probability to \"drop-out\" one neuron is 0.3)\n",
        "- (2a) a layer of `LSTM` with $n_a$=256\n",
        "- (2b) a layer of DropOut with rate 0.3 (the probability to \"drop-out\" one neuron is 0.3)\n",
        "- (3) a layer of `LSTM` with $n_a$=256\n",
        "- (4a) a layer of `Dense` with 256 units and a `ReLU` activation\n",
        "- (4b) a layer of DropOut with rate 0.3 (the probability to \"drop-out\" one neuron is 0.3)\n",
        "- (5) a layer of `Dense` with a `softmax` activation which predict the probability of each of the $n_x$ notes as output\n",
        "\n",
        "## Returning the hidden states at each time of an LSTM cell\n",
        "\n",
        "Note that when we stack one LSTM layer on top of a second LSTM layer (deep-RNN), we need to tell the first LSTM to output its hidden states at each time $t$. This is done by the option `return_sequences=True` that has to be given as parameter to the LSTM on top of the other one.\n",
        "This is the case for (1a) and (2a).\n",
        "\n",
        "However, since we are only interrested in the last hidden state of the third LSTM (since we are only interrest in its prediction at time $T_x$), we give the option `return_sequences=False` (which is the default behaviour) for the third LSTM.\n",
        "This is the case for (3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epWHM4p6D5n7"
      },
      "outputs": [],
      "source": [
        "# --- Create the model\n",
        "K.clear_session()\n",
        "\n",
        "if student:\n",
        "    # --- START CODE HERE (02)\n",
        "    model = ...\n",
        "    # --- END CODE HERE\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhWTNfIbFDmf"
      },
      "outputs": [],
      "source": [
        "# --- Compile and fit the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM6g1YR3gtcO"
      },
      "source": [
        "# Generating a new sequence from sampling the language model\n",
        "\n",
        "To generate a new sequence from the language model, we simply give it as input a random sequence of duration ```sequence_length```and ask the trained network to predict the output (using ```model.predict```). \n",
        "\n",
        "The output of the network is a vector of probability of dimension $n_x$ which represents the probability of each note to be the next note of the melody given as input.\n",
        "\n",
        "From this vector, we select the note which has the maximum probability.\n",
        "\n",
        "We then concatenate this new note (its one-hot-encoding representation) at the end of the input sequence.\n",
        "We finally remove the first element of the input sequence to keep its duration constant (```sequence_length```).\n",
        "\n",
        "Instead of providing a random sequence as input, we rather randomly select one sequence out of the 23.781 sequences used for training.\n",
        "\n",
        "- The ```pattern``` variable is the ```list``` of init notes to which we progressively append the new generated notes by the model.\n",
        "- The ```prediction``` variable is a ```list``` which stores the softmax probability vector (a numpy array) corresponding to each generation time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YHXTohsFGCX"
      },
      "outputs": [],
      "source": [
        "# --- Select a random starting pattern\n",
        "start = np.random.randint(0, len(X_train_list)-1)\n",
        "pattern = X_train_list[start]\n",
        "print(start)\n",
        "print(pattern.shape)\n",
        "print(np.expand_dims(pattern, 0).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_ADCs7uFW8m"
      },
      "outputs": [],
      "source": [
        "# --- note_l: is the list of notes (integer number) over time\n",
        "note_l = []\n",
        "# --- prediction_l: is the list of output-vectors (float numbers \\in [0,1]) of the network over time\n",
        "prediction_l = []\n",
        "# --- Generate T_y_generated notes\n",
        "for note_index in range(T_y_generated):\n",
        "    if student:\n",
        "        # --- START CODE HERE (03)\n",
        "        prediction = ...\n",
        "        pattern = ...\n",
        "        # --- END CODE HERE    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stQscvNOg0xd"
      },
      "source": [
        "### Display the generated sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9IOPPiuLuHE"
      },
      "outputs": [],
      "source": [
        "print(note_l)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.imshow(np.asarray(prediction_l)[:,0,:].T, aspect='auto', origin='lower')\n",
        "plt.plot(note_l)\n",
        "plt.set_cmap('gray_r')\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwM6osfDg5E0"
      },
      "source": [
        "### Create a MIDI file and an audio file which correspond to the generated sequence\n",
        "\n",
        "Once the new sequence has been generated (```note_l```) we transform it to a new MIDI file and perform (a very cheap) rendering of it in an audio file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cpTszOFID51"
      },
      "outputs": [],
      "source": [
        "new_midi_data = pretty_midi.PrettyMIDI()\n",
        "cello_program = pretty_midi.instrument_name_to_program('Cello')\n",
        "cello = pretty_midi.Instrument(program=cello_program)\n",
        "time = 0\n",
        "step = 0.3\n",
        "for note_number in note_l:\n",
        "    myNote = pretty_midi.Note(velocity=100, pitch=note_number, start=time, end=time+step)\n",
        "    cello.notes.append(myNote)\n",
        "    time += step\n",
        "new_midi_data.instruments.append(cello)\n",
        "new_midi_data.write('output.mid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yOXBXxa3IGKW"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "audio_data = new_midi_data.synthesize(fs=44100)\n",
        "IPython.display.Audio(audio_data, rate=44100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb4DLCWjj93s"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "To evaluate the work, you should rate the code for \n",
        "- 1) Data conversion for the training of language model (01)\n",
        "- 2) Training the language model (02)\n",
        "- 3) Generating a new sequence from sampling the language model (03)\n",
        "\n",
        "You will also rate the answer to the four questions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgjoIxEqL7bx"
      },
      "source": [
        "## Question 1)\n",
        "\n",
        "What happens if we replace the LSTM cell by a RNNsimple cell?\n",
        "\n",
        "**Answer below** (1 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIstqiBzj93v"
      },
      "source": [
        "Answer: ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTB7qV8wj93y"
      },
      "source": [
        "## Question 2) \n",
        "\n",
        "What happens if we shorten the length of the sequences used for training? How can this effect be avoided?\n",
        "\n",
        "**Answer below** (1 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAuSUBH4j932"
      },
      "source": [
        "Answer: ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46IzXO5Wj935"
      },
      "source": [
        "## Question 3) \n",
        "\n",
        "How could we make the system polyphonic (several notes played simultaneously by the same instrument)? for training? for generation?\n",
        "\n",
        "**Answer below** (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAyxRPQoj937"
      },
      "source": [
        "Answer: ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7MlNRsxj93-"
      },
      "source": [
        "## Question 4) \n",
        "\n",
        "We used a simplified procedure to train the musical language model, transforming the learning into a Many-To-one problem. Explain ? How does one usually train a language model with an RNN? What would be the advantage?\n",
        "\n",
        "**Answer below** (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJgs4uwpj94Q"
      },
      "source": [
        "Answer: ..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}