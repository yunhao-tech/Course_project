{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPf2yufekv0f"
      },
      "source": [
        "\n",
        "# TP CNN, part 3 : super-resolution\n",
        "\n",
        "Author : Alasdair Newson\n",
        "alasdair.newson@telecom-paris.fr\n",
        " \n",
        "## Objective:\n",
        "\n",
        "We want to implement a Convolutional Neural Network (CNN) to do image super-resolution.\n",
        "\n",
        "## Image super-resolution:\n",
        "\n",
        "The super-resolution problem can be summarised as follows. We have an image as an input, which is defined over a grid $\\{0,1,\\dots, m-1\\} \\times \\{0,1,\\dots, n-1\\}$. We define a factor $\\delta$, by which we upsample the image. The output of the super-resolution is an image defined on the grid $\\{0,\\frac{1}{\\delta},\\dots, m-1\\} \\times \\{0,\\frac{1}{\\delta},\\dots, n-1\\}$.\n",
        "\n",
        "## Model\n",
        "\n",
        "In this part of the TP, you have complete freedom to create any model you want, as long as the input is an image, and the output is also an image of size $\\delta m \\times \\delta n$. You will have to choose the architecture and loss which seems reasonable to you.\n",
        "\n",
        "To help you, here is a function to upsample images in neural networks :\n",
        "\n",
        "- ```from tensorflow.keras.layers import UpSampling2D```\n",
        "\n",
        "Of course, you can use any upsampling layer you wish. \n",
        "\n",
        "## Dataset\n",
        "\n",
        "We will be using the mnist dataset for this part. This is to ensure that you can obtain good results. The input data should be the subsampled version of the mnist images, subsampled by taking one out of every $\\delta$ pixels. The output data should be the normal-resolution mnist images.\n",
        "\n",
        "__IMPORTANT NOTES:__\n",
        "- Think carefully about what the training data and labels are in this case, and create them accordingly\n",
        "- We will use ```n_max=5000``` to limit the number of datapoints (as in part 1) to go faster\n",
        "- We set $\\delta$ to 2 in this TP, because it is not too difficult to create a network that works with this factor. If you change it, it might be more difficult to create a satisfactory network.\n",
        "\n",
        "# Your task:\n",
        "You have to load the mnist data (see the first part of the TP), create the model, train it, and evaluate and display the results.\n",
        "\n",
        "We have created a function ```super_res_interpolate```, which carries out super-resolution using basic interpolation (bilinear or bicubic), with which you can compare your results visually and numerically.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5utO2_UDyKs3"
      },
      "source": [
        "\n",
        "# # Load packages\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras import optimizers\n",
        "from scipy import interpolate\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcXyExW4vgmk"
      },
      "source": [
        "This next cell is the only code you are given to carry out the TP. This function carries out a bilinear upsampling, with which you can compare your super-resolution. This function is __not__ supposed to be used by you in your network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np3Dj3tuqEqn"
      },
      "source": [
        "# choice of the interpolation method\n",
        "interp_method = 'linear'\n",
        "# upsampling factor\n",
        "delta = 2\n",
        "# the maximum number of data to take from mnist (to go a bit faster)\n",
        "n_max = 5000\n",
        "\n",
        "# upsample by a factor of delta\n",
        "# by definition, the new grid has a step size of 1/delta\n",
        "def super_res_interpolate(imgs_in,delta,interp_method = 'linear'):\n",
        "\timgs_out = tf.image.resize( tf.constant(imgs_in),\\\n",
        "\t\t[delta*imgs_in.shape[1],delta*imgs_in.shape[2]], method='bilinear').numpy()\n",
        "\n",
        "\treturn(imgs_out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLGjn0zP5h0V"
      },
      "source": [
        "## Create your super-resolution network\n",
        "\n",
        "The rest is up to you ! Import the data, format it (you can use the first part of the TP as help), create your network, train it, and compare the results with ```super_res_interpolate```.\n",
        "\n",
        "Your network should be able to achieve about $80\\%$ accuracy.\n",
        "\n",
        "__Note__ you can obviously create as many cells as you like in your work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfx5BxeUqKf-"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}