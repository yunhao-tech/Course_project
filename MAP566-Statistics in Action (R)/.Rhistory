#| code-fold: false
library(tidyverse)
library(lme4)
library(lattice)
theme_set(theme_bw())
data(Orange)
## we force the sorting of the levels (1,2,3)
Orange$Tree <- factor(Orange$Tree, levels = unique(Orange$Tree))
Orange %>% as_tibble() %>% rmarkdown::paged_table()
#| code-fold: true
pl <-
Orange %>%
ggplot() + aes(x = age, y = circumference, color = Tree) +
geom_point() + geom_line()
pl
names(Orange)
str(Orange)
#
lm1 <- lm(circumference~age:Tree, data=Orange)
pl + geom_line(aes(x = age, y = predict(lm1))) + theme_bw()
#
lm1 <- lm(circumference~age:Tree, data=Orange)
pl + geom_line(aes(x = age, y = predict(lm1))) + facet_wrap(~Tree) + theme_bw()
# different slope and different intercept for different tree
lm2 <- lm(circumference~age:Tree + Tree, data=Orange)
pl + geom_line(aes(x = age, y = predict(lm2))) + facet_wrap(~Tree) + theme_bw()
# compare these two models
anova(lm1, lm2)
BIc(lm1, lm2)
BIC(lm1, lm2)
# compare these two models
anova(lm1, lm2)
BIC(lm1, lm2)
AIC(lm1, lm2)
lmem1 <- lmer(circumference ~ age + (age|Subject), data = Orange)
lmem1 <- lmer(circumference ~ age + (age|Tree), data = Orange)
pl + geom_line(aes(x = age, y = predict(lmem1))) + facet_wrap(~Tree) + theme_bw()
lm1 <- lm(circumference~age+0, data=Orange)
pl + geom_line(aes(x = age, y = predict(lm1))) + facet_wrap(~Tree) + theme_bw()
lm2 <- lm(circumference~age, data=Orange)
pl + geom_line(aes(x = age, y = predict(lm2))) + facet_wrap(~Tree) + theme_bw()
# compare these two models
anova(lm1, lm2)
BIC(lm1, lm2)
AIC(lm1, lm2)
# it seems that lm1 is better
# compare these two models
anova(lm2, lm1)
BIC(lm1, lm2)
AIC(lm1, lm2)
# it seems that lm1 is better
# random effect only on intercept
lmem1 <- lmer(circumference ~ age + (1|Tree), data = Orange)
# random effect only on slope
lmem2 <- lmer(circumference ~ age + (age + 0|Tree), data = Orange)
# random effect on intercept and slope
lmem3 <- lmer(circumference ~ age + (age|Tree), data = Orange)
BIC(lmem1, lmem2, lmem3, lm1, lm2)
pl + geom_line(aes(x = age, y = predict(lmem2))) + facet_wrap(~Tree) + theme_bw()
confint(lmem2)
data(Pastes)
Pastes %>% as_tibble() %>% rmarkdown::paged_table()
Pastes %>%
group_by(batch, cask) %>%
summarise(mean_strengh = mean(strength), sd_strength = sd(strength), n_replicat = n()) %>%
rmarkdown::paged_table()
#| code-fold: true
Pastes %>%
ggplot() + aes(x = fct_reorder(batch, strength, median), y = strength) + geom_boxplot() + geom_jitter()
#| code-fold: true
lattice::dotplot(cask ~ strength | reorder(batch, strength), Pastes,
strip = FALSE, strip.left = TRUE, layout = c(1, 10),
ylab = "Cask within batch",
xlab = "Paste strength", jitter.y = TRUE)
lm0 <- lm(strength~1, data = Pastes)
lm1 <- lm(strength~batch + 0, data = Pastes)
lm2 <- lm(strength~batch + cask + 0, data = Pastes)
BIC(lm0, lm1, lm2)
lm1
lm0
lm2
lm0 <- lm(strength~1, data = Pastes)
lm1 <- lm(strength~batch + 0, data = Pastes)
lm2 <- lm(strength~batch + batch:cask + 0, data = Pastes)
lm2
lmem1 <- lmer(strength ~ 1 + (1|batch), data = Pastes)
lmem2 <- lmer(strength ~ 1 + (1|batch:cask), data = Pastes)
BIC(lmem1, lmem2, lm0, lm1, lm2)
# random effect only on intercept
lmem1 <- lmer(circumference ~ age + (1|Tree), data = Orange)
# random effect only on slope
lmem2 <- lmer(circumference ~ age + (age + 0|Tree), data = Orange)
# random effect on intercept and slope
lmem3 <- lmer(circumference ~ 1+age + (1+age|Tree), data = Orange)
BIC(lmem1, lmem2, lmem3, lm1, lm2)
# it seems that lmem2 (random effect only on slope) is the best.
# lmem2 and lmem3 do the similar prediction. BIC choose the one with less parameters.
# Attention to the df!
# lm1: sigma(variance of noise), intercept
# lm2: sigma(variance of noise), intercept, slope of age
# lmem1: sigma(variance of noise), intercept, slope of age, variance of random effects on Tree for intercept
# lmem3: sigma(variance of noise), intercept, slope of age,
# variance of random effects on Tree for slope of age,
# variance of random effects on intercept,
# covariance of these two above
lm1 <- lm(circumference~age+0, data=Orange)
pl + geom_line(aes(x = age, y = predict(lm1))) + facet_wrap(~Tree) + theme_bw()
lm2 <- lm(circumference~age, data=Orange)
pl + geom_line(aes(x = age, y = predict(lm2))) + facet_wrap(~Tree) + theme_bw()
BIC(lmem1, lmem2, lmem3, lm1, lm2)
# it seems that lmem2 (random effect only on slope) is the best.
# lmem2 and lmem3 do the similar prediction. BIC choose the one with less parameters.
# Attention to the df!
# lm1: sigma(variance of noise), intercept
# lm2: sigma(variance of noise), intercept, slope of age
# lmem1: sigma(variance of noise), intercept, slope of age, variance of random effects on Tree for intercept
# lmem3: sigma(variance of noise), intercept, slope of age,
# variance of random effects on Tree for slope of age,
# variance of random effects on intercept,
# covariance of these two above
library(igraph)     # graph manipulation
library(igraph)     # graph manipulation
library(igraphdata) # network data manipulation
library(tidyverse)  # data manipulation
library(corrplot)   # fancy matrix representation
library(aricode)    # clustering measures comparison
data("UKfaculty", package = "igraphdata")
UKfaculty <- as.undirected(UKfaculty)
UKfaculty
UKbinary <- UKfaculty
E(UKbinary)$weight <- rep(1, length(E(UKbinary)$weight))
E(UKbinary)$weight
length(E(UKbinary)$weight)
affiliation <- V(UKfaculty)$Group
plot(UKbinary, vertex.color = affiliation)
summary(UKbinary)
plot.igraph(UKfaculty,
vertex.color = factor(V(UKfaculty)$Group),
vertex.label = NA
)
affiliation <- V(UKfaculty)$Group
plot(UKbinary, vertex.color = affiliation)
summary(UKbinary)
plot.igraph(UKfaculty,
vertex.color = factor(V(UKfaculty)$Group)
)
plot.igraph(UKfaculty,
vertex.color = (V(UKfaculty)$Group)
)
UKbinary <- UKfaculty
n_edges <- gsize(UKfaculty)
E(UKbinary)$weight <- rep(1, n_edges)
plot.igraph(UKfaculty,
vertex.color = factor(V(UKfaculty)$Group)
)
plot.igraph(UKbinary,
vertex.color = factor(V(UKbinary)$Group)
)
affiliation <- V(UKfaculty)$Group
plot.igraph(UKbinary, vertex.color = affiliation)
summary(UKbinary)
UKbinary %>% as_adjacency_matrix() %>%
corrplot(is.corr = FALSE, tl.pos = 'n', cl.pos = 'n')
UKbinary %>% as_adjacency_matrix()
# %>% corrplot(is.corr = FALSE, tl.pos = 'n', cl.pos = 'n')
UKbinary %>% as_adjacency_matrix() %>% corrplot(is.corr = FALSE, tl.pos = 'n', cl.pos = 'n')
UKbinary %>% as_adjacency_matrix() %>% as.matrix() %>% corrplot(is.corr = FALSE, tl.pos = 'n', cl.pos = 'n')
Y <- UKbinary %>% as_adjacency_matrix() %>% as.matrix()
Y %>% corrplot(is.corr = FALSE, tl.pos = 'n', cl.pos = 'n')
order(affiliation)
Y <- UKbinary %>% as_adjacency_matrix() %>% as.matrix()
o <- order(affiliation)
Y[o,o] %>% corrplot(is.corr = FALSE, tl.pos = 'n', cl.pos = 'n')
hist(degree(UKbinary))
D_shortest <- distances(UKbinary)
corrplot(D_shortest, is.corr = FALSE, tl.pos = 'n')
D_shortest <- distances(UKbinary)
or <- order(D_shortest)
corrplot(D_shortest[or, or], is.corr = FALSE, tl.pos = 'n')
dim(D_shortest)
dim(or)
or
D_shortest <- distances(UKbinary)
corrplot(D_shortest, is.corr = FALSE, tl.pos = 'n')
hc_modularity  <- igraph::cluster_fast_greedy(UKbinary)
hc_betweenness <- igraph::cluster_edge_betweenness(UKbinary)
hc_louvain     <- igraph::cluster_louvain(UKbinary)
plot(hc_modularity, UKbinary)
plot(hc_betweenness, UKbinary)
plot(hc_louvain, UKbinary)
hist(D_shortest)
corrplot(D_shortest[o,o], is.corr = FALSE, tl.pos = 'n')
corrplot(D_shortest[o,o], is.corr = FALSE, tl.pos = 'n')
hc_path <- hclust(as.dist(D_shortest), method = "ward.D2")
plot(hc_path, labels = FALSE)
plot(hc_path)
shortest_path_cl <- cutree(hc_path, 4)
table(affiliation, shortest_path_cl)
ARI(affiliation, shortest_path_cl)
plot(hc_modularity)
hc_modularity
table(affiliation, cutree(hc_modularity, 4))
modularity_cl <- cutree(as.hclust(hc_modularity), 4)
table(affiliation, modularity_cl)
ARI(affiliation, modularity_cl)
UKfaculty %>%
as_adj(attr= "weight") %>%
as.matrix() %>%
corrplot(is.corr = FALSE, tl.pos = 'n', cl.pos = 'n')
plot(UKbinary,
vertex.color = affiliation,
vertex.size = degree(UKfaculty),
edge.width = .1 * E(UKfaculty)$weight)
Y_weighted <- UKfaculty %>% as_adj(attr= "weight") %>% as.matrix()
Y_weighted[o,o] %>% corrplot(is.corr = FALSE, tl.pos = 'n', cl.pos = 'n')
plot(UKbinary,
vertex.color = affiliation,
vertex.size = degree(UKfaculty),
edge.width = .1 * E(UKfaculty)$weight)
plot(UKbinary,
vertex.color = affiliation,
vertex.size = degree(UKfaculty),
edge.width =  E(UKfaculty)$weight)
plot(UKbinary,
vertex.color = affiliation,
vertex.size = degree(UKfaculty),
edge.width = .1 *E(UKfaculty)$weight)
hc_modularity <- as.hclust(igraph::cluster_fast_greedy(UKfaculty))
hc_short_path <- hclust(as.dist(igraph::distances(UKfaculty)), method = "ward.D2")
plot(hc_modularity)
plot(hc_short_path)
nb_cluster <- 1:10
perf <- data.frame(
nb_cluster = nb_cluster,
modularity    = apply(cutree(hc_modularity , nb_cluster), 2, ARI, affiliation),
shortest_path = apply(cutree(hc_short_path , nb_cluster), 2, ARI, affiliation))
perf %>%
pivot_longer(-nb_cluster, names_to = "method", values_to = "ARI") %>%
group_by(method) %>%
ggplot() + aes(x = nb_cluster, y = ARI, color = method) + geom_line() +
theme_bw()
L <- laplacian_matrix(UKfaculty, normalized = TRUE)
spec_L <- eigen(L)
practical_zero <- 1e-12
lambda  <- min(spec_L$values[spec_L$values>practical_zero])
fiedler <- spec_L$vectors[, which(spec_L$values == lambda)]
qplot(y = fiedler, color = factor(affiliation)) + theme_bw()
spectral_clustering <- function(graph, nb_cluster, normalized = TRUE) {
L <- laplacian_matrix(graph, normalized = normalized)
selected <- rev(1:ncol(L))[1:nb_cluster]
U <- eigen(L)$vectors[, selected, drop = FALSE] # spectral decomposition
if (nb_cluster > 1) U <- sweep(U, 1, sqrt(rowSums(U^2)), '/')
U[is.na(U)] <- 0
res <- kmeans(U, nb_cluster, nstart = 40)
res
}
absolute_spectral_clustering <- function(graph, nb_cluster) {
L <- laplacian_matrix(graph, normalized = TRUE)
AL <- diag(1, ncol(L), ncol(L)) - L
spec_AL <- eigen(AL)
selected <- order(abs(spec_AL$values), decreasing = TRUE)[1:nb_cluster]
U <- spec_AL$vectors[, selected, drop = FALSE]
if (nb_cluster > 1) U <- sweep(U, 1, sqrt(rowSums(U^2)), '/')
U[is.na(U)] <- 0
res <- kmeans(U, nb_cluster, nstart = 40)
res
}
nb_cluster <- 1:10
sp_norm   <- map(nb_cluster, ~spectral_clustering(UKfaculty, .))
sp_abs    <- map(nb_cluster, ~absolute_spectral_clustering(UKfaculty, .))
A <- UKfaculty %>%  as_adj(attr= "weight") %>% as.matrix()
par(mf.row = c(1,3))
corrplot(A[order(affiliation), order(affiliation)], title = "reordering: affilation", is.corr=FALSE)
corrplot(A[order(sp_norm[[4]]$cl), order(sp_norm[[4]]$cl)], title = "reordering: normalized spectral", is.corr=FALSE)
corrplot(A[order(sp_abs[[4]]$cl), order(sp_abs[[4]]$cl)], title = "reordering: absolute spectral", is.corr=FALSE)
perf$spectral_normalized <- map_dbl(sp_norm, function(sp) ARI(sp$cl, affiliation))
perf$spectral_absolute   <- map_dbl(sp_abs , function(sp) ARI(sp$cl, affiliation))
perf %>%
pivot_longer(-nb_cluster, names_to = "method", values_to = "ARI") %>%
group_by(method) %>%
ggplot() + aes(x = nb_cluster, y = ARI, color = method) + geom_line() +
theme_bw()
?pivot_longer
A <- UKfaculty %>%  as_adj(attr= "weight") %>% as.matrix()
par(mf.row = c(1,3))
corrplot(A[order(affiliation), order(affiliation)], title = "reordering: affilation", is.corr=FALSE, label_value=NA)
corrplot(A[order(sp_norm[[4]]$cl), order(sp_norm[[4]]$cl)], title = "reordering: normalized spectral", is.corr=FALSE)
corrplot(A[order(sp_abs[[4]]$cl), order(sp_abs[[4]]$cl)], title = "reordering: absolute spectral", is.corr=FALSE)
corrplot(A[order(affiliation), order(affiliation)], title = "reordering: affilation", is.corr=FALSE, tl.pos = 'n')
hist(degree(UKfaculty))
plot(UKfaculty,
vertex.color = affiliation,
vertex.size = degree(UKfaculty),
edge.width = .1 *E(UKfaculty)$weight)
?sweep
sp_norm
sp_norm[[4]]$cl
sp_norm[[4]]
